{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "행렬 분해 기반의 잠재 요인 협업필터링의 핵심은 사용자-아이템 평점 매트릭스 속에 숨어있는 잠재 요인을 추출해서 영화 별 예측 평점을 계산해 영화 등 아이템 추천을 가능하게 해주는 것입니다.\n",
    "\n",
    "실제 평점 행렬(R)을 행렬 분해(Matrix Factorization) 기법으로 분해해서 잠재 요인을 추출합니다.\n",
    "\n",
    "이 행렬 분해(MF) 기법은 넷플릭스 경연 대회에서 사용되면서 유명해졌습니다.\n",
    "이 후 많은 추천시스템이 행렬 분해에 기반한 잠재 요인 협업필터링을 적용하고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사하강법을 이용한 행렬 분해 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 4., nan, nan,  2., nan],\n",
       "       [nan,  5., nan,  3.,  1.],\n",
       "       [nan, nan,  3.,  4.,  4.],\n",
       "       [ 5.,  2.,  1.,  2., nan]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 원본 행렬 R 생성, \n",
    "# 분해 행렬 P와 Q 초기화, 잠재요인 차원 K는 3 설정. \n",
    "R = np.array([[4, np.NaN, np.NaN, 2, np.NaN ],\n",
    "              [np.NaN, 5, np.NaN, 3, 1 ],\n",
    "              [np.NaN, np.NaN, 3, 4, 4 ],\n",
    "              [5, 2, 1, 2, np.NaN ]])\n",
    "\n",
    "print(R.shape)\n",
    "R # R은 4X5 행렬이다."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Matrix Factorization\n",
    ": 행렬 R을 행렬 P, Q로 분해해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "num_users, num_items = R.shape\n",
    "\n",
    "K=3  # 잠재 요인은 3개\n",
    "\n",
    "print(num_users) # M\n",
    "print(num_items) # N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.54144845 -0.2039188  -0.17605725]\n",
      " [-0.35765621  0.28846921 -0.76717957]\n",
      " [ 0.58160392 -0.25373563  0.10634637]\n",
      " [-0.08312346  0.48736931 -0.68671357]] \n",
      "\n",
      "[[-0.1074724  -0.12801812  0.37792315]\n",
      " [-0.36663042 -0.05747607 -0.29261947]\n",
      " [ 0.01407125  0.19427174 -0.36687306]\n",
      " [ 0.38157457  0.30053024  0.16749811]\n",
      " [ 0.30028532 -0.22790929 -0.04096341]]\n"
     ]
    }
   ],
   "source": [
    "# P, Q 찾기\n",
    "# P와 Q 매트릭스의 크기를 지정하고 정규분포를 가진 random한 값으로 입력합니다.\n",
    "np.random.seed(1)\n",
    "\n",
    "P = np.random.normal(scale=1./K, size=(num_users, K))  # 4X3 P행렬\n",
    "Q = np.random.normal(scale=1./K, size=(num_items, K))  # 5X3 Q행렬\n",
    "\n",
    "# 행렬 P, Q 초기화 상태\n",
    "print(P,'\\n')\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "비용계산 함수를 생성하고,\n",
    "분해된 행렬 P와 Q.T를 내적하여 예측 행렬을 생성한다.\n",
    "\n",
    "실제 행렬에서 null이 아닌 위치 값만 에측 행렬의 값과 비교하여 RMSE(오차) 값을 계산하고 반환한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# 실제 행렬 R과 예측 행렬 간 오차(RMSE)를 구하는 함수\n",
    "# R 행렬에서 비어있지 않은 값 : non_zeros\n",
    "def get_rmse(R, P, Q, non_zeros):\n",
    "    error = 0\n",
    "    # 두개의 분해된 행렬 P와 Q.T의 내적으로 예측 R 행렬 생성\n",
    "    full_pred_matrix = np.dot(P, Q.T)\n",
    "    \n",
    "    # 실제 R 행렬에서 널이 아닌 값의 위치 인덱스 추출하여 실제 R 행렬과 예측 행렬의 RMSE 추출\n",
    "    x_non_zero_ind = [non_zero[0] for non_zero in non_zeros]\n",
    "    y_non_zero_ind = [non_zero[1] for non_zero in non_zeros]\n",
    "    R_non_zeros = R[x_non_zero_ind, y_non_zero_ind]\n",
    "    full_pred_matrix_non_zeros = full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
    "      \n",
    "    mse = mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 경사하강법에 기반하여 P와 Q 원소들을 업데이트 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0, 4.0),\n",
       " (0, 3, 2.0),\n",
       " (1, 1, 5.0),\n",
       " (1, 3, 3.0),\n",
       " (1, 4, 1.0),\n",
       " (2, 2, 3.0),\n",
       " (2, 3, 4.0),\n",
       " (2, 4, 4.0),\n",
       " (3, 0, 5.0),\n",
       " (3, 1, 2.0),\n",
       " (3, 2, 1.0),\n",
       " (3, 3, 2.0)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# R > 0 인 행 위치, 열 위치, 값을 non_zeros 리스트에 저장. \n",
    "non_zeros = [ (i, j, R[i,j]) for i in range(num_users) for j in range(num_items) if R[i,j] > 0 ]\n",
    "non_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4., nan, nan,  2., nan],\n",
       "       [nan,  5., nan,  3.,  1.],\n",
       "       [nan, nan,  3.,  4.,  4.],\n",
       "       [ 5.,  2.,  1.,  2., nan]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 경사하강법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### iteration step :  0  rmse :  0.016410959588961445\n",
      "### iteration step :  50  rmse :  0.01637308966218993\n",
      "### iteration step :  100  rmse :  0.016333882336881784\n",
      "### iteration step :  150  rmse :  0.016293661274599174\n",
      "### iteration step :  200  rmse :  0.01625272572302336\n",
      "### iteration step :  250  rmse :  0.016211338984681307\n",
      "### iteration step :  300  rmse :  0.016169725523756753\n",
      "### iteration step :  350  rmse :  0.016128072491623933\n",
      "### iteration step :  400  rmse :  0.016086533303745463\n",
      "### iteration step :  450  rmse :  0.016045231961723017\n",
      "### iteration step :  500  rmse :  0.016004267423347165\n",
      "### iteration step :  550  rmse :  0.015963717671935662\n",
      "### iteration step :  600  rmse :  0.01592364333325902\n",
      "### iteration step :  650  rmse :  0.015884090797210332\n",
      "### iteration step :  700  rmse :  0.01584509485896164\n",
      "### iteration step :  750  rmse :  0.015806680922219037\n",
      "### iteration step :  800  rmse :  0.01576886681829548\n",
      "### iteration step :  850  rmse :  0.015731664296432853\n",
      "### iteration step :  900  rmse :  0.0156950802377121\n",
      "### iteration step :  950  rmse :  0.015659117639502156\n",
      "### iteration step :  1000  rmse :  0.01562377641126073\n",
      "### iteration step :  1050  rmse :  0.015589054016349555\n",
      "### iteration step :  1100  rmse :  0.015554945988861105\n",
      "### iteration step :  1150  rmse :  0.015521446349450352\n",
      "### iteration step :  1200  rmse :  0.015488547939747707\n",
      "### iteration step :  1250  rmse :  0.01545624269135677\n",
      "### iteration step :  1300  rmse :  0.015424521842295272\n",
      "### iteration step :  1350  rmse :  0.015393376111282013\n",
      "### iteration step :  1400  rmse :  0.015362795838183143\n",
      "### iteration step :  1450  rmse :  0.015332771097284762\n",
      "### iteration step :  1500  rmse :  0.015303291788717931\n",
      "### iteration step :  1550  rmse :  0.015274347712285622\n",
      "### iteration step :  1600  rmse :  0.015245928627081148\n",
      "### iteration step :  1650  rmse :  0.015218024299612717\n",
      "### iteration step :  1700  rmse :  0.01519062454260429\n",
      "### iteration step :  1750  rmse :  0.01516371924620075\n",
      "### iteration step :  1800  rmse :  0.015137298402981364\n",
      "### iteration step :  1850  rmse :  0.015111352127906257\n",
      "### iteration step :  1900  rmse :  0.015085870674095652\n",
      "### iteration step :  1950  rmse :  0.01506084444518256\n",
      "### iteration step :  2000  rmse :  0.015036264004844877\n",
      "### iteration step :  2050  rmse :  0.015012120083998748\n",
      "### iteration step :  2100  rmse :  0.01498840358605898\n",
      "### iteration step :  2150  rmse :  0.01496510559059199\n",
      "### iteration step :  2200  rmse :  0.014942217355656108\n",
      "### iteration step :  2250  rmse :  0.014919730319020604\n",
      "### iteration step :  2300  rmse :  0.01489763609849127\n",
      "### iteration step :  2350  rmse :  0.014875926491473183\n",
      "### iteration step :  2400  rmse :  0.014854593473919212\n",
      "### iteration step :  2450  rmse :  0.014833629198763576\n",
      "### iteration step :  2500  rmse :  0.014813025993944972\n",
      "### iteration step :  2550  rmse :  0.014792776360095143\n",
      "### iteration step :  2600  rmse :  0.014772872967945041\n",
      "### iteration step :  2650  rmse :  0.01475330865553506\n",
      "### iteration step :  2700  rmse :  0.014734076425243908\n",
      "### iteration step :  2750  rmse :  0.014715169440695331\n",
      "### iteration step :  2800  rmse :  0.014696581023572753\n",
      "### iteration step :  2850  rmse :  0.01467830465036814\n",
      "### iteration step :  2900  rmse :  0.014660333949087112\n",
      "### iteration step :  2950  rmse :  0.014642662695939187\n",
      "### iteration step :  3000  rmse :  0.014625284812012095\n",
      "### iteration step :  3050  rmse :  0.01460819435996789\n",
      "### iteration step :  3100  rmse :  0.014591385540748595\n",
      "### iteration step :  3150  rmse :  0.014574852690323055\n",
      "### iteration step :  3200  rmse :  0.014558590276459728\n",
      "### iteration step :  3250  rmse :  0.014542592895555768\n",
      "### iteration step :  3300  rmse :  0.014526855269506886\n",
      "### iteration step :  3350  rmse :  0.01451137224263225\n",
      "### iteration step :  3400  rmse :  0.01449613877865972\n",
      "### iteration step :  3450  rmse :  0.01448114995776735\n",
      "### iteration step :  3500  rmse :  0.014466400973686197\n",
      "### iteration step :  3550  rmse :  0.014451887130863955\n",
      "### iteration step :  3600  rmse :  0.014437603841691987\n",
      "### iteration step :  3650  rmse :  0.014423546623797264\n",
      "### iteration step :  3700  rmse :  0.014409711097395934\n",
      "### iteration step :  3750  rmse :  0.014396092982709248\n",
      "### iteration step :  3800  rmse :  0.014382688097442095\n",
      "### iteration step :  3850  rmse :  0.014369492354327223\n",
      "### iteration step :  3900  rmse :  0.014356501758723004\n",
      "### iteration step :  3950  rmse :  0.014343712406279092\n",
      "### iteration step :  4000  rmse :  0.014331120480660299\n",
      "### iteration step :  4050  rmse :  0.014318722251323433\n",
      "### iteration step :  4100  rmse :  0.014306514071356878\n",
      "### iteration step :  4150  rmse :  0.014294492375373094\n",
      "### iteration step :  4200  rmse :  0.014282653677457987\n",
      "### iteration step :  4250  rmse :  0.014270994569174628\n",
      "### iteration step :  4300  rmse :  0.014259511717616401\n",
      "### iteration step :  4350  rmse :  0.014248201863514512\n",
      "### iteration step :  4400  rmse :  0.01423706181939126\n",
      "### iteration step :  4450  rmse :  0.014226088467771594\n",
      "### iteration step :  4500  rmse :  0.014215278759425303\n",
      "### iteration step :  4550  rmse :  0.014204629711678884\n",
      "### iteration step :  4600  rmse :  0.014194138406747773\n",
      "### iteration step :  4650  rmse :  0.014183801990134531\n",
      "### iteration step :  4700  rmse :  0.01417361766905545\n",
      "### iteration step :  4750  rmse :  0.014163582710913203\n",
      "### iteration step :  4800  rmse :  0.014153694441813634\n",
      "### iteration step :  4850  rmse :  0.014143950245116632\n",
      "### iteration step :  4900  rmse :  0.0141343475600332\n",
      "### iteration step :  4950  rmse :  0.014124883880247905\n",
      "### iteration step :  5000  rmse :  0.014115556752591091\n",
      "### iteration step :  5050  rmse :  0.014106363775739877\n",
      "### iteration step :  5100  rmse :  0.014097302598953015\n",
      "### iteration step :  5150  rmse :  0.014088370920841385\n",
      "### iteration step :  5200  rmse :  0.014079566488169845\n",
      "### iteration step :  5250  rmse :  0.01407088709469682\n",
      "### iteration step :  5300  rmse :  0.014062330580034354\n",
      "### iteration step :  5350  rmse :  0.014053894828546331\n",
      "### iteration step :  5400  rmse :  0.014045577768272512\n",
      "### iteration step :  5450  rmse :  0.014037377369886158\n",
      "### iteration step :  5500  rmse :  0.0140292916456684\n",
      "### iteration step :  5550  rmse :  0.01402131864852231\n",
      "### iteration step :  5600  rmse :  0.01401345647100259\n",
      "### iteration step :  5650  rmse :  0.014005703244382219\n",
      "### iteration step :  5700  rmse :  0.013998057137729173\n",
      "### iteration step :  5750  rmse :  0.013990516357020002\n",
      "### iteration step :  5800  rmse :  0.01398307914427166\n",
      "### iteration step :  5850  rmse :  0.013975743776693264\n",
      "### iteration step :  5900  rmse :  0.01396850856586751\n",
      "### iteration step :  5950  rmse :  0.01396137185694408\n",
      "### iteration step :  6000  rmse :  0.013954332027865302\n",
      "### iteration step :  6050  rmse :  0.013947387488600476\n",
      "### iteration step :  6100  rmse :  0.01394053668040675\n",
      "### iteration step :  6150  rmse :  0.013933778075111267\n",
      "### iteration step :  6200  rmse :  0.013927110174402289\n",
      "### iteration step :  6250  rmse :  0.01392053150915238\n",
      "### iteration step :  6300  rmse :  0.01391404063874427\n",
      "### iteration step :  6350  rmse :  0.013907636150427338\n",
      "### iteration step :  6400  rmse :  0.013901316658681695\n",
      "### iteration step :  6450  rmse :  0.013895080804602509\n",
      "### iteration step :  6500  rmse :  0.013888927255298783\n",
      "### iteration step :  6550  rmse :  0.013882854703307622\n",
      "### iteration step :  6600  rmse :  0.013876861866024109\n",
      "### iteration step :  6650  rmse :  0.01387094748514887\n",
      "### iteration step :  6700  rmse :  0.01386511032613944\n",
      "### iteration step :  6750  rmse :  0.01385934917768834\n",
      "### iteration step :  6800  rmse :  0.013853662851201997\n",
      "### iteration step :  6850  rmse :  0.013848050180308056\n",
      "### iteration step :  6900  rmse :  0.013842510020358403\n",
      "### iteration step :  6950  rmse :  0.013837041247954849\n",
      "### iteration step :  7000  rmse :  0.013831642760483653\n",
      "### iteration step :  7050  rmse :  0.013826313475664922\n",
      "### iteration step :  7100  rmse :  0.013821052331108119\n",
      "### iteration step :  7150  rmse :  0.013815858283881774\n",
      "### iteration step :  7200  rmse :  0.01381073031009254\n",
      "### iteration step :  7250  rmse :  0.013805667404476866\n",
      "### iteration step :  7300  rmse :  0.013800668580000446\n",
      "### iteration step :  7350  rmse :  0.013795732867468909\n",
      "### iteration step :  7400  rmse :  0.013790859315145714\n",
      "### iteration step :  7450  rmse :  0.013786046988381907\n",
      "### iteration step :  7500  rmse :  0.01378129496925629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### iteration step :  7550  rmse :  0.013776602356221078\n",
      "### iteration step :  7600  rmse :  0.01377196826375449\n",
      "### iteration step :  7650  rmse :  0.013767391822029278\n",
      "### iteration step :  7700  rmse :  0.013762872176581498\n",
      "### iteration step :  7750  rmse :  0.013758408487991588\n",
      "### iteration step :  7800  rmse :  0.0137539999315711\n",
      "### iteration step :  7850  rmse :  0.013749645697062225\n",
      "### iteration step :  7900  rmse :  0.01374534498832819\n",
      "### iteration step :  7950  rmse :  0.013741097023079494\n",
      "### iteration step :  8000  rmse :  0.013736901032575848\n",
      "### iteration step :  8050  rmse :  0.013732756261356473\n",
      "### iteration step :  8100  rmse :  0.013728661966969202\n",
      "### iteration step :  8150  rmse :  0.013724617419703945\n",
      "### iteration step :  8200  rmse :  0.013720621902338151\n",
      "### iteration step :  8250  rmse :  0.013716674709881046\n",
      "### iteration step :  8300  rmse :  0.013712775149333204\n",
      "### iteration step :  8350  rmse :  0.013708922539439035\n",
      "### iteration step :  8400  rmse :  0.013705116210458688\n",
      "### iteration step :  8450  rmse :  0.013701355503937637\n",
      "### iteration step :  8500  rmse :  0.013697639772479604\n",
      "### iteration step :  8550  rmse :  0.01369396837953047\n",
      "### iteration step :  8600  rmse :  0.013690340699165063\n",
      "### iteration step :  8650  rmse :  0.013686756115878097\n",
      "### iteration step :  8700  rmse :  0.013683214024377863\n",
      "### iteration step :  8750  rmse :  0.01367971382938824\n",
      "### iteration step :  8800  rmse :  0.013676254945456075\n",
      "### iteration step :  8850  rmse :  0.013672836796757345\n",
      "### iteration step :  8900  rmse :  0.013669458816912996\n",
      "### iteration step :  8950  rmse :  0.013666120448807181\n",
      "### iteration step :  9000  rmse :  0.013662821144405757\n",
      "### iteration step :  9050  rmse :  0.013659560364587504\n",
      "### iteration step :  9100  rmse :  0.013656337578971441\n",
      "### iteration step :  9150  rmse :  0.013653152265753025\n",
      "### iteration step :  9200  rmse :  0.013650003911534082\n",
      "### iteration step :  9250  rmse :  0.013646892011173847\n",
      "### iteration step :  9300  rmse :  0.013643816067627287\n",
      "### iteration step :  9350  rmse :  0.013640775591791821\n",
      "### iteration step :  9400  rmse :  0.013637770102365837\n",
      "### iteration step :  9450  rmse :  0.013634799125695573\n",
      "### iteration step :  9500  rmse :  0.013631862195636335\n",
      "### iteration step :  9550  rmse :  0.013628958853411898\n",
      "### iteration step :  9600  rmse :  0.013626088647480267\n",
      "### iteration step :  9650  rmse :  0.013623251133396385\n",
      "### iteration step :  9700  rmse :  0.013620445873686984\n",
      "### iteration step :  9750  rmse :  0.013617672437717847\n",
      "### iteration step :  9800  rmse :  0.013614930401572582\n",
      "### iteration step :  9850  rmse :  0.013612219347927912\n",
      "### iteration step :  9900  rmse :  0.013609538865934903\n",
      "### iteration step :  9950  rmse :  0.013606888551101658\n"
     ]
    }
   ],
   "source": [
    "steps=10000\n",
    "learning_rate=0.01\n",
    "r_lambda=0.01\n",
    "\n",
    "# P와 Q 매트릭스를 계속 업데이트(확률적 경사하강법)\n",
    "for step in range(steps):  # 1000회 업데이트\n",
    "    for i, j, r in non_zeros:\n",
    "        \n",
    "        # 실제 값과 예측 값의 차이인 오류 값 구함\n",
    "        eij = r - np.dot(P[i, :], Q[j, :].T)\n",
    "        \n",
    "        # Regularization을 반영한 SGD(확률적 경사하강법) 업데이트 공식 적용\n",
    "        P[i,:] = P[i,:] + learning_rate * ( eij * Q[j,:] - r_lambda*P[i,:] )\n",
    "        Q[j,:] = Q[j,:] + learning_rate * ( eij * P[i,:] - r_lambda*Q[j,:] )\n",
    "\n",
    "    rmse = get_rmse(R, P, Q, non_zeros)\n",
    "    if (step % 50) == 0 :\n",
    "        print(\"### iteration step : \", step,\" rmse : \", rmse)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "실제 행렬과 예측 행렬 간 오차를 최소화하는 방향(rmse 감소)으로 경사하강법 진행\n",
    "-> P와 Q 행렬이 업데이트 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 행렬:\n",
      " [[3.991 1.974 1.106 1.997 1.563]\n",
      " [4.097 4.978 1.113 2.987 1.005]\n",
      " [4.932 2.581 2.988 3.98  3.984]\n",
      " [4.974 2.001 1.003 2.002 1.555]]\n"
     ]
    }
   ],
   "source": [
    "pred_matrix = np.dot(P, Q.T)\n",
    "print('예측 행렬:\\n', np.round(pred_matrix, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4., nan, nan,  2., nan],\n",
       "       [nan,  5., nan,  3.,  1.],\n",
       "       [nan, nan,  3.,  4.,  4.],\n",
       "       [ 5.,  2.,  1.,  2., nan]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 원본 행렬 R\n",
    "R"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "원래 값은 예측 행렬과 실제 행렬 값이 최대한 비슷하게 만들어진 것을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
